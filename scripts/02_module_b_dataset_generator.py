#!/usr/bin/env python3
"""
MODULE B â€” SYNTHETIC RAW DATA GENERATOR (REALISTIC VARIANCE EDITION)

Purpose
-------
Generate RAW operational-style datasets for the Insurance Analytics platform,
with realistic month-to-month portfolio variability while preserving
annual control totals.

Key Improvements vs previous version
------------------------------------
âœ” Monthly policy growth is NO LONGER uniform
âœ” Annual totals remain deterministic and controlled
âœ” Seasonality + macro noise applied to new business
âœ” Executive dashboards no longer show linear ramps
âœ” Downstream schema and BI contracts unchanged

Outputs (RAW)
-------------
- clients.csv
- policies.csv
- claims.csv
- expenses.csv
- taxes.csv
"""

from __future__ import annotations

import os
import json
from datetime import date, datetime, timedelta
from pathlib import Path
from typing import Dict, Any, List

import numpy as np
import pandas as pd

# ============================================================
# PATHS
# ============================================================

CONFIG_PATH = os.path.join("output", "config.json")
RAW_DIR = os.path.join("output", "raw")


# ============================================================
# BASIC UTILITIES
# ============================================================

def ensure_dir(path: str) -> None:
    """Create directory if it does not exist."""
    os.makedirs(path, exist_ok=True)


def load_config(path: str = CONFIG_PATH) -> Dict[str, Any]:
    """Load configuration generated by Module A."""
    if not os.path.exists(path):
        raise FileNotFoundError(f"Config not found: {path}")
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def save_csv(name: str, df: pd.DataFrame) -> None:
    """Persist a dataframe into output/raw."""
    ensure_dir(RAW_DIR)
    out = os.path.join(RAW_DIR, f"{name}.csv")
    df.to_csv(out, index=False)
    print(f"[OK] {name}.csv â†’ {len(df):,} rows")


def parse_date_iso(s: str) -> date:
    """Parse YYYY-MM-DD string into date."""
    return datetime.strptime(s, "%Y-%m-%d").date()


def clamp(x: float, lo: float, hi: float) -> float:
    """Bound a numeric value between lo and hi."""
    return max(lo, min(hi, x))


# ============================================================
# CLIENT GENERATION
# ============================================================

def generate_clients(cfg: Dict[str, Any], rng: np.random.Generator) -> pd.DataFrame:
    """
    Generate cumulative active clients by year.
    Churn is NOT modeled explicitly; the portfolio grows monotonically.
    """

    states = cfg["organization"]["states"]
    years = [int(y) for y in cfg["time"]["years"]]
    by_year = cfg["portfolio"]["by_year"]

    target_clients = [int(by_year[str(y)]["active_clients"]) for y in years]

    rows = []
    client_id = 1
    previous_total = 0

    for year, target in zip(years, target_clients):
        new_clients = target - previous_total

        if new_clients < 0:
            raise RuntimeError("Client churn not supported in this scenario")

        if new_clients == 0:
            previous_total = target
            continue

        state_idx = rng.integers(0, len(states), size=new_clients)
        ages = np.clip(rng.normal(45, 16, size=new_clients).astype(int), 18, 84)
        genders = rng.choice(["Male", "Female"], size=new_clients)
        segments = rng.choice(["Individual", "Corporate"], p=[0.9, 0.1], size=new_clients)

        capacity_draw = rng.random(size=new_clients)
        max_policies = np.where(
            capacity_draw < 0.60, 1,
            np.where(capacity_draw < 0.90, 2, 3)
        )

        for i in range(new_clients):
            st = states[state_idx[i]]
            rows.append({
                "client_id": f"C{client_id:07d}",
                "registration_year": year,
                "age": int(ages[i]),
                "gender": genders[i],
                "state_code": st["state_code"],
                "region_code": st["region_code"],
                "market_tier": st["market_tier"],
                "customer_segment": segments[i],
                "max_policies_allowed": int(max_policies[i]),
            })
            client_id += 1

        previous_total = target

    df = pd.DataFrame(rows)

    if df.empty or df["client_id"].duplicated().any():
        raise RuntimeError("Client generation failed")

    return df


def client_capacity_for_year(
    registration_year: int,
    base_capacity: int,
    current_year: int
) -> int:
    """
    Allow natural cross-sell over time.
    Capacity increases slowly after registration.
    """
    if current_year <= registration_year:
        return base_capacity
    return base_capacity + min(2, current_year - registration_year)


def compute_risk_score(
    age: int,
    segment: str,
    risk_std: float,
    rng: np.random.Generator
) -> float:
    """
    Produce a bounded risk score with demographic effects + noise.
    """
    score = 5.0

    if age < 26:
        score += 1.5
    elif age < 36:
        score += 0.5
    elif age > 65:
        score += 2.5
    elif age > 50:
        score += 1.0

    if segment == "Corporate":
        score -= 0.3

    score += rng.normal(0, risk_std)

    return float(np.clip(round(score, 2), 1.0, 10.0))


def allocate_policies_by_month(
    total_policies: int,
    rng: np.random.Generator
) -> np.ndarray:
    """
    Allocate annual new policies across months using:
    - Base seasonality
    - Macro noise
    - Exact preservation of annual total
    """

    # Typical insurance seasonality (new business)
    base_weights = np.array([
        0.07, 0.07, 0.08, 0.08,
        0.09, 0.10, 0.10, 0.09,
        0.08, 0.08, 0.08, 0.08
    ])

    # Add macro volatility (business cycles, campaigns, etc.)
    noise = rng.normal(loc=1.0, scale=0.15, size=12)
    noisy_weights = base_weights * noise

    # Prevent degenerate months
    noisy_weights = np.clip(noisy_weights, 0.02, None)

    # Normalize to sum to 1
    weights = noisy_weights / noisy_weights.sum()

    # Multinomial guarantees total preservation
    monthly_counts = rng.multinomial(total_policies, weights)

    return monthly_counts


def generate_policies(
    cfg: Dict[str, Any],
    clients_df: pd.DataFrame,
    rng: np.random.Generator
) -> pd.DataFrame:
    """
    Generate policies with realistic monthly variation while keeping
    annual portfolio targets intact.
    """

    years = [int(y) for y in cfg["time"]["years"]]
    by_year = cfg["portfolio"]["by_year"]
    products = cfg["products"]

    start_date = parse_date_iso(cfg["time"]["start_date"])
    end_date = parse_date_iso(cfg["time"]["end_date"])

    # Annual stock â†’ annual delta
    annual_stock = [int(by_year[str(y)]["estimated_policies"]) for y in years]
    annual_delta = [annual_stock[0]] + [
        annual_stock[i] - annual_stock[i - 1]
        for i in range(1, len(annual_stock))
    ]

    usage = pd.Series(0, index=clients_df["client_id"].values)
    policy_rows = []
    policy_id = 1

    lob_choices = np.array(["Health", "Auto", "Life"])
    lob_probs = np.array([0.45, 0.35, 0.20])

    plan_names = {
        "Life": list(products["Life"].keys()),
        "Health": list(products["Health"].keys()),
        "Auto": list(products["Auto"].keys()),
    }

    for year, new_policies in zip(years, annual_delta):

        if new_policies <= 0:
            continue

        # ðŸ”¥ NEW: allocate per month
        monthly_counts = allocate_policies_by_month(new_policies, rng)

        eligible = clients_df[clients_df["registration_year"] <= year].copy()

        capacity = eligible.apply(
            lambda r: client_capacity_for_year(
                int(r["registration_year"]),
                int(r["max_policies_allowed"]),
                year
            ),
            axis=1
        )

        used = usage.loc[eligible["client_id"]].values
        remaining_capacity = capacity.values - used

        # Relax capacity slightly if needed
        relax_round = 0
        while remaining_capacity.sum() < new_policies:
            relax_round += 1
            if relax_round > 3:
                raise RuntimeError(f"Capacity failure in year {year}")
            remaining_capacity += 1

        pool = np.repeat(eligible["client_id"].values, remaining_capacity)
        rng.shuffle(pool)

        chosen_clients = pool[:new_policies]
        usage.loc[pd.Series(chosen_clients).value_counts().index] += \
            pd.Series(chosen_clients).value_counts().values

        # Build policy rows month by month
        idx = 0
        for month, count in enumerate(monthly_counts, start=1):
            for _ in range(count):

                client_id_val = chosen_clients[idx]
                client_row = clients_df.loc[
                    clients_df["client_id"] == client_id_val
                ].iloc[0]

                lob = rng.choice(lob_choices, p=lob_probs)
                plan = rng.choice(plan_names[lob])
                base_premium = products[lob][plan]["base_monthly_premium"]

                risk_std = rng.uniform(
                    *cfg["volatility_model"]["risk_score_std_dev_range"]
                )

                risk_score = compute_risk_score(
                    age=int(client_row["age"]),
                    segment=str(client_row["customer_segment"]),
                    risk_std=risk_std,
                    rng=rng
                )

                effective_date = date(year, month, 1)
                expiration_date = min(
                    effective_date + timedelta(days=364),
                    end_date
                )

                policy_rows.append({
                    "policy_id": f"P{policy_id:08d}",
                    "policy_number": f"POL-{year}-{policy_id:06d}",
                    "client_id": client_id_val,
                    "line_of_business": lob,
                    "plan_name": plan,
                    "state_code": client_row["state_code"],
                    "region_code": client_row["region_code"],
                    "effective_date": effective_date.isoformat(),
                    "expiration_date": expiration_date.isoformat(),
                    "status": "Active",
                    "is_renewal": bool(client_row["registration_year"] < year),
                    "risk_score": risk_score,
                    "monthly_premium": round(base_premium, 2),
                    "annual_premium": round(base_premium * 12, 2),
                })

                policy_id += 1
                idx += 1

        print(f"[OK] Policies {year}: +{new_policies:,}")

    df = pd.DataFrame(policy_rows)

    if df.empty or df["policy_id"].duplicated().any():
        raise RuntimeError("Policy generation failed")

    return df


# ============================================================
# CLAIMS GENERATION
# ============================================================

CLAIM_TYPES = {
    "Life": (
        np.array(["Death", "Terminal_Illness", "Disability"]),
        np.array([0.80, 0.12, 0.08])
    ),
    "Health": (
        np.array(["Hospitalization", "Surgery", "Emergency_Room",
                  "Specialist_Visit", "Prescription"]),
        np.array([0.30, 0.20, 0.18, 0.20, 0.12])
    ),
    "Auto": (
        np.array(["Collision", "Liability", "Theft",
                  "Weather_Damage", "Vandalism"]),
        np.array([0.40, 0.25, 0.10, 0.10, 0.15])
    )
}

CLAIM_STATUS = (
    np.array(["Paid", "Pending", "Denied"]),
    np.array([0.80, 0.13, 0.07])
)


def generate_claims(
    cfg: Dict[str, Any],
    policies_df: pd.DataFrame,
    rng: np.random.Generator
) -> pd.DataFrame:
    """
    Generate claims based on exposure, seasonality and volatility.
    """

    end = parse_date_iso(cfg["time"]["end_date"])
    baseline_freq = cfg["claims"]["baseline_frequency"]

    pol = policies_df.copy()
    pol["eff"] = pd.to_datetime(pol["effective_date"])
    pol["exp"] = pd.to_datetime(pol["expiration_date"])

    pol = pol[pol["eff"] <= pol["exp"]]

    exposure_days = (pol["exp"] - pol["eff"]).dt.days + 1
    year_fraction = exposure_days / 365.0

    freq_noise = rng.uniform(
        *cfg["volatility_model"]["claim_frequency_noise_range"],
        size=len(pol)
    )

    seasonality = pol["eff"].dt.month.map(
        lambda m: cfg["claims"]["seasonality_by_month"][str(m)]
    ).values

    climate = pol["state_code"].map(
        lambda s: cfg["claims"]["climate_sensitivity_by_state"]
        .get(s, cfg["claims"]["default_climate_factor"])
    ).values

    base_freq = pol["line_of_business"].map(
        lambda lob: baseline_freq[lob]
    ).values

    lam = base_freq * seasonality * climate * freq_noise * year_fraction
    lam = np.clip(lam, 0, None)

    claim_counts = rng.poisson(lam)
    total_claims = int(claim_counts.sum())

    if total_claims == 0:
        raise RuntimeError("No claims generated")

    pol_idx = np.repeat(pol.index.values, claim_counts)
    claims_pol = pol.loc[pol_idx].reset_index(drop=True)

    incident_offsets = rng.integers(
        0,
        (claims_pol["exp"] - claims_pol["eff"]).dt.days.values + 1
    )

    incident_dates = claims_pol["eff"] + pd.to_timedelta(
        incident_offsets, unit="D"
    )

    report_dates = incident_dates + pd.to_timedelta(
        rng.integers(0, 31, size=total_claims), unit="D"
    )
    report_dates = report_dates.map(lambda d: min(d.date(), end))

    # Claim types
    claim_types = []
    for lob in claims_pol["line_of_business"]:
        types, probs = CLAIM_TYPES[lob]
        claim_types.append(rng.choice(types, p=probs))

    # Claim statuses
    status_values, status_probs = CLAIM_STATUS
    statuses = rng.choice(
        status_values,
        size=total_claims,
        p=status_probs
    )

    requested = np.zeros(total_claims)
    approved = np.zeros(total_claims)
    paid = np.zeros(total_claims)

    for i in range(total_claims):
        lob = claims_pol.at[i, "line_of_business"]
        base_amt = rng.lognormal(mean=9, sigma=0.8)

        if lob == "Life":
            base_amt *= 10
        elif lob == "Health":
            base_amt *= 1.5

        req = round(base_amt, 2)
        requested[i] = req

        if statuses[i] == "Denied":
            approved[i] = 0.0
            paid[i] = 0.0
        else:
            ratio = rng.uniform(0.75, 0.95)
            approved[i] = round(req * ratio, 2)
            paid[i] = approved[i] if statuses[i] == "Paid" else 0.0

    # Correctly indented return statement
    return pd.DataFrame({
        "claim_id": [f"CL{i+1:09d}" for i in range(total_claims)],
        "policy_id": claims_pol["policy_id"].values,
        "incident_date": incident_dates.dt.date.astype(str),
        "report_date": report_dates.astype(str),
        "claim_type": claim_types,
        "claim_amount_requested": requested,
        "claim_amount_approved": approved,
        "claim_amount_paid": paid,
        "claim_status": statuses,
    })



# ============================================================
# EXPENSES GENERATION
# ============================================================

def generate_expenses(cfg: Dict[str, Any], rng: np.random.Generator) -> pd.DataFrame:
    """
    Generate monthly operating expenses by state.
    """

    start = parse_date_iso(cfg["time"]["start_date"])
    end = parse_date_iso(cfg["time"]["end_date"])

    months = pd.date_range(
        start=date(start.year, start.month, 1),
        end=date(end.year, end.month, 1),
        freq="MS"
    )

    rows = []
    expense_id = 1

    for ms in months:
        for st in cfg["organization"]["states"]:
            base = {
                "Tier 1": rng.uniform(40_000, 50_000),
                "Tier 2": rng.uniform(30_000, 40_000),
                "Tier 3": rng.uniform(25_000, 33_000),
            }[st["market_tier"]]

            noise = rng.uniform(0.9, 1.1)

            rows.append({
                "expense_id": expense_id,
                "expense_category": "Operating",
                "state_code": st["state_code"],
                "region_code": st["region_code"],
                "expense_month": ms.date().isoformat(),
                "expense_amount": round(base * noise, 2),
            })
            expense_id += 1

    return pd.DataFrame(rows)


# ============================================================
# TAXES GENERATION
# ============================================================

def generate_taxes(
    cfg: Dict[str, Any],
    policies_df: pd.DataFrame,
    rng: np.random.Generator
) -> pd.DataFrame:
    """
    Generate premium taxes per policy.
    """

    tier_rate = {
        "Tier 1": 0.035,
        "Tier 2": 0.030,
        "Tier 3": 0.025,
    }

    state_tier = {
        s["state_code"]: s["market_tier"]
        for s in cfg["organization"]["states"]
    }

    rows = []
    tax_id = 1

    for _, r in policies_df.iterrows():
        tier = state_tier[r["state_code"]]
        rate = tier_rate[tier] * rng.uniform(0.95, 1.05)

        taxable = r["annual_premium"]
        tax = round(taxable * rate, 2)

        rows.append({
            "tax_id": tax_id,
            "policy_id": r["policy_id"],
            "state_code": r["state_code"],
            "tax_amount": tax,
            "tax_rate": round(rate, 4),
        })
        tax_id += 1

    return pd.DataFrame(rows)


# ============================================================
# MAIN
# ============================================================

def main() -> None:
    print("MODULE B â€” START")

    cfg = load_config()
    rng = np.random.default_rng(cfg["meta"].get("random_seed", 42))

    ensure_dir(RAW_DIR)

    print("Generating clients...")
    clients = generate_clients(cfg, rng)
    save_csv("clients", clients)

    print("Generating policies (monthly-variant growth)...")
    policies = generate_policies(cfg, clients, rng)
    save_csv("policies", policies)

    print("Generating claims...")
    claims = generate_claims(cfg, policies, rng)
    save_csv("claims", claims)

    print("Generating expenses...")
    expenses = generate_expenses(cfg, rng)
    save_csv("expenses", expenses)

    print("Generating taxes...")
    taxes = generate_taxes(cfg, policies, rng)
    save_csv("taxes", taxes)

    print("\nMODULE B â€” COMPLETED SUCCESSFULLY")
    print("Generated RAW datasets:")
    for f in ["clients", "policies", "claims", "expenses", "taxes"]:
        print(f" - {f}.csv")

if __name__ == "__main__":
    main()

